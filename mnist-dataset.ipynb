{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments.\n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. There have been a number of scientific papers on attempts to achieve the lowest error rate; one paper, using a hierarchical system of convolutional neural networks, manages to get an error rate on the MNIST database of 0.23%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "Import gzip and unzip the zipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapted from https://docs.python.org/3/library/gzip.html\n",
    "import gzip\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Endian & Little Endian\n",
    "This illustrates how the data is composed \n",
    "![title](img/label.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Endian Byte Order: \n",
    "The most significant byte (the \"big end\") of the data is placed at the byte with the lowest address. The rest of the data is placed in order in the next three bytes in memory.\n",
    "\n",
    "#### Little Endian Byte Order: \n",
    "The least significant byte (the \"little end\") of the data is placed at the byte with the lowest address. The rest of the data is placed in order in the next three bytes in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(file_content) ## file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x03'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[0:4], byteorder= 'big') ## magic number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[4:8], byteorder= 'big') ## number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[8:12], byteorder= 'big') ## pixel size rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(file_content[12:16], byteorder= 'big') ## pixel size columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the bits into a 28 x 28 array using the numpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ## imports the numpy package\n",
    "\n",
    "image = ~np.array(list(file_content[16:800])).reshape(28,28).astype(np.uint8) ## reshapes the list into  28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use matplotlib to display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt ## imports the matplotlib package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the first image\n",
    "The image resembles the number five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fc94b99304ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m## display the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(image, cmap='gray')## display the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ~np.array(list(file_content[800:1584])).reshape(28,28).astype(np.uint8) ## 800+784 = 1584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20138598438>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f: \n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(labels[4:8], byteorder=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first label should be 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "label = int.from_bytes(labels[8:9], byteorder=\"big\") \n",
    "print(str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second label should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "label = int.from_bytes(labels[9:10], byteorder=\"big\") \n",
    "print(str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras.\n",
    "import keras as kr\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add a 10 neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "    \n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8)\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_img.reshape(60000, 784)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.8977 - acc: 0.7486\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.3861 - acc: 0.8834\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.3177 - acc: 0.9034\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.2775 - acc: 0.9160\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.2466 - acc: 0.9254\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.2250 - acc: 0.9321: 3\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.2058 - acc: 0.9384\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1897 - acc: 0.9430\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1745 - acc: 0.9480\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1621 - acc: 0.9512\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1543 - acc: 0.9541\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1423 - acc: 0.9578\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1343 - acc: 0.9604\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1259 - acc: 0.9626\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1201 - acc: 0.9640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2013d056ef0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=15, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8)\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9587"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refrences\n",
    "* [MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "* [GZIP](https://docs.python.org/3/library/gzip.html)\n",
    "* [Deep Learning](http://deeplearning.net/tutorial/gettingstarted.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
